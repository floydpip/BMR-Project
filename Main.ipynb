{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d3f80b1c",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Imports\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d0c718f-5917-4819-99a3-ff65decc7385",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "!pip install dijkstar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4c5ccdbf",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "# Import opencv for computer vision\n",
    "import cv2 \n",
    "# Import matplotlib to visualize an image\n",
    "from matplotlib import pyplot as plt\n",
    "from __future__ import print_function\n",
    "import sys\n",
    "from random import randint\n",
    "import cv2.aruco as aruco\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63eccd2e-c5e6-4071-b4a3-af22cfd8c294",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Computer Vision\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a5caefb-ea92-47ee-b3d1-cca0b7bd3742",
   "metadata": {},
   "source": [
    "## Past attempts:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5caf6d2-4163-4acd-a552-321c640b5925",
   "metadata": {},
   "source": [
    "Potential solutions:\n",
    "1. Using Tensorflow\n",
    "https://www.youtube.com/watch?v=yqkISICHH-U\n",
    "\n",
    "2. Using MultiTracker OpenCV\n",
    "https://learnopencv.com/multitracker-multiple-object-tracking-using-opencv-c-python/"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf612f29-2d0d-40ca-aa47-fbd7f3805bb2",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Using MultiTracker OpenCV\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "500c9b0c-e56b-4e5d-a61b-5992536998ac",
   "metadata": {
    "tags": []
   },
   "source": [
    "Start by creating a single object tracker\n",
    "- below doesnt work"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a4c0fbf-c8c4-4aa8-adba-a1076a6d4ca6",
   "metadata": {},
   "source": [
    "Read the first frame of livestream\n",
    "* May need to modify"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed8ac18f-f09d-4823-a99b-288c82f55aa4",
   "metadata": {},
   "source": [
    "Locate objects in the first frame"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32d297e7-c7b8-42e1-9a80-d1c535c04651",
   "metadata": {
    "tags": []
   },
   "source": [
    "Check out\n",
    "https://www.youtube.com/watch?v=8ktcGQ-XreQ"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0cfdb7f4-327c-48e1-8248-0f143f946aa0",
   "metadata": {},
   "source": [
    "Perhaps use YOLOv5:\n",
    "https://blog.paperspace.com/train-yolov5-custom-data/\n",
    "\n",
    "\n",
    "https://blog.roboflow.com/how-to-train-yolov5-on-a-custom-dataset/\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90eb01b0-fe78-4ca6-9075-2a5f99dcde9a",
   "metadata": {},
   "source": [
    "## 1. Setting up Aruco"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "039b53f0-8e51-4980-a3f7-637e99f33074",
   "metadata": {},
   "source": [
    "### Markers detected in real time:\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28abf90a-e51a-4029-8751-7d7958f4d966",
   "metadata": {},
   "source": [
    "Code referenced from:\n",
    "https://docs.opencv.org/4.8.0/d5/dae/tutorial_aruco_detection.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "892d0b1b-b9b3-418d-bd10-c9db69a1d85a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "from cv2 import aruco\n",
    "\n",
    "cap = cv2.VideoCapture(1, cv2.CAP_DSHOW)\n",
    "\n",
    "# Camera matrix\n",
    "camera_matrix = np.array([[20.10654304, 0, 84.16362263],\n",
    "                          [0, 20.34239482, 95.42267081],\n",
    "                          [0, 0, 1]])\n",
    "\n",
    "# Distortion coefficients\n",
    "distortion_coefficients = np.array([[-9.40501496e-04, 3.73198946e-05, -2.32754445e-03, 3.95213785e-04, -6.01340412e-07]])\n",
    "\n",
    "while True:\n",
    "    ret, frame = cap.read()\n",
    "    gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "    aruco_dict = aruco.getPredefinedDictionary(cv2.aruco.DICT_5X5_50)\n",
    "    parameters = aruco.DetectorParameters()\n",
    "    detector = aruco.ArucoDetector(aruco_dict, parameters)\n",
    "\n",
    "    corners, ids, rejected_img_points = detector.detectMarkers(gray)\n",
    "\n",
    "    if np.all(ids is not None):\n",
    "        for i in range(0, len(ids)):\n",
    "            #rvec, tvec, _ = aruco.estimatePoseSingleMarkers(corners[i], 0.02, camera_matrix, distortion_coefficients)\n",
    "            aruco.drawDetectedMarkers(frame, corners, ids)\n",
    "            #cv2.drawFrameAxes(frame, camera_matrix, distortion_coefficients, rvec, tvec, 0.02)\n",
    "\n",
    "    cv2.imshow('frame', frame)\n",
    "\n",
    "    key = cv2.waitKey(3) & 0xFF\n",
    "    if key == ord('q'):\n",
    "        break\n",
    "\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "390e5b07-6f9b-405f-9707-1482489bdfd6",
   "metadata": {},
   "source": [
    "### Getting marker coordinates\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b80a512f-cce8-47bc-9df0-5eaaea4781d9",
   "metadata": {},
   "source": [
    "Thymio: &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;index 0\n",
    "<br>\n",
    "Obstacles:&nbsp;&nbsp;&nbsp;indicies 1-6\n",
    "<br>\n",
    "Goal:&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;index 7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c48c1dfc-bd62-4df5-9ecd-3043c0ea2473",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def current_photo():\n",
    "    cap = cv2.VideoCapture(1, cv2.CAP_DSHOW)\n",
    "    ret, frame = cap.read()\n",
    "    cv2.imwrite('images/current.jpg', frame)\n",
    "    cap.release()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28441c67-b620-464a-a9ec-5ca8c025e0ca",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "current_photo()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "829b9cfd-5fe1-4175-aa48-e18fe1f060ee",
   "metadata": {},
   "source": [
    "The following functions below retrieve the first photo, and utilize it to locate the coordinates of the markers.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41c70e70-af28-4157-a757-3655dc345c2f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def get_Thymio():\n",
    "    img_path = 'images/current.jpg'\n",
    "    img = cv2.imread(img_path)\n",
    "    gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)  # Change grayscale\n",
    "    aruco_dict = aruco.getPredefinedDictionary(cv2.aruco.DICT_5X5_50)  # Use 5x5 dictionary to find markers\n",
    "    parameters = aruco.DetectorParameters()  \n",
    "    detector = aruco.ArucoDetector(aruco_dict, parameters)\n",
    "\n",
    "    corners, ids, rejected_img_points = detector.detectMarkers(gray)\n",
    " \n",
    "    # Get thymio at idx 0  \n",
    "    idx_back = np.where(ids == 0)[0][0]\n",
    "    idx_fowards = np.where(ids == 1)[0][0]\n",
    "    idx = [idx_back, idx_fowards]\n",
    "    coords = [corners[i].tolist() for i in idx]  \n",
    "    \n",
    "    center = []\n",
    "    for i in coords:\n",
    "        # Get center coordinates to return\n",
    "        x1 = i[0][0][0]\n",
    "        y1 = i[0][0][1]\n",
    "        x2 = i[0][2][0]\n",
    "        y2 = i[0][2][1]\n",
    "\n",
    "        x_center = (x1 + x2) / 2\n",
    "        y_center = (y1 + y2) / 2\n",
    "    \n",
    "        center.append([x_center, y_center])\n",
    "    return center\n",
    "    \n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58d6d232-b32c-48ad-a377-f561ea1f141c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "center_thymio = get_Thymio()\n",
    "print(center_thymio)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef78f556-71b5-4942-a8e6-98398b5e6be4",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def get_goal():\n",
    "    img_path = 'images/current.jpg'\n",
    "    img = cv2.imread(img_path)\n",
    "    gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)  # Change grayscale\n",
    "    aruco_dict = aruco.getPredefinedDictionary(cv2.aruco.DICT_5X5_50)  # Use 5x5 dictionary to find markers\n",
    "    parameters = aruco.DetectorParameters()  \n",
    "    detector = aruco.ArucoDetector(aruco_dict, parameters)\n",
    "\n",
    "    corners, ids, rejected_img_points = detector.detectMarkers(gray)\n",
    "    \n",
    "    # If aruco markers are detected:\n",
    "    # if np.all(ids is not None):\n",
    "      #  output_image = gray.copy()\n",
    "        #aruco.drawDetectedMarkers(output_image,corners) \n",
    "                    \n",
    "    # Get goal at idx 7  \n",
    "    idx = np.where(ids == 7)[0][0]\n",
    "    coords = corners[idx]\n",
    "    \n",
    "      \n",
    "    \n",
    "    # Get center coordinates to return\n",
    "    x1 = coords[0][0][0]\n",
    "    y1 = coords[0][0][1]\n",
    "    x2 = coords[0][2][0]\n",
    "    y2 = coords[0][2][1]\n",
    "    \n",
    "    x_center = (x1 + x2) / 2\n",
    "    y_center = (y1 + y2) / 2\n",
    "    \n",
    "    center = [x_center, y_center]\n",
    "    \n",
    "    return center"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35e1430e-dade-482b-9e1d-d72f365cfd51",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "center_goal = get_goal()\n",
    "print(center_goal)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04ccc3d0-1a4d-4cdd-b75d-1fde5e7745f6",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def get_obst():\n",
    "    img_path = 'images/current.jpg'\n",
    "    img = cv2.imread(img_path)\n",
    "    gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)  # Change grayscale\n",
    "    aruco_dict = aruco.getPredefinedDictionary(cv2.aruco.DICT_5X5_50)  # Use 5x5 dictionary to find markers\n",
    "    parameters = aruco.DetectorParameters()  \n",
    "    detector = aruco.ArucoDetector(aruco_dict, parameters)\n",
    "\n",
    "    corners, ids, rejected_img_points = detector.detectMarkers(gray)\n",
    "    \n",
    "    # If aruco markers are detected:\n",
    "    # if np.all(ids is not None):\n",
    "      #  output_image = gray.copy()\n",
    "        #aruco.drawDetectedMarkers(output_image,corners) \n",
    "                    \n",
    "    # Get obstacles at idx that is not Thymio or goal \n",
    "    idx = np.where((ids != 0) & (ids != 7) & (ids != 1))[0]\n",
    "    coord = [corners[i].tolist() for i in idx]\n",
    "    print(\"Coord\",coord)\n",
    "    id = ids[idx]\n",
    "    print(\"ID\", id)\n",
    "    \n",
    "    coords_list = []\n",
    "\n",
    "    for i in coord:    \n",
    "        ul_x = i[0][0][0]\n",
    "        ul_y = i[0][0][1]\n",
    "\n",
    "        ur_x = i[0][1][0]\n",
    "        ur_y = i[0][1][1]\n",
    "\n",
    "        br_x = i[0][2][0]\n",
    "        br_y = i[0][2][1]\n",
    "\n",
    "        bl_x = i[0][3][0]\n",
    "        bl_y = i[0][3][1]\n",
    "\n",
    "        coords_list.append([ul_x, ul_y, ur_x, ur_y, bl_x, bl_y, br_x, br_y])\n",
    "        \n",
    "    # Sort coords based on id\n",
    "    coords = [x for y, x in sorted(zip(id, coords_list))]\n",
    "    return coords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97be335a-07f8-4fc1-a9ee-20d9304f5f36",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "obstacle_coord = get_obst()\n",
    "print(obstacle_coord)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ee809ad-a93a-4709-be9f-903e3a8e203d",
   "metadata": {},
   "source": [
    "# Path Planning"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f712d7c-71ee-409f-adb3-0b9ec55b3239",
   "metadata": {},
   "source": [
    "## 1. Dijkstra Algorithm"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b27e29a-10df-49ad-b5b1-d0d57207ccc2",
   "metadata": {},
   "source": [
    "I am still fine-tuning the computer vision code. For now, use this image as a reference and and these coordinates to begin working on the algorithm.\n",
    "\n",
    "Img height: 640\n",
    "Img width: 640"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee327adf-fc6a-4ee0-bb14-5f14c9fd407a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from PIL import Image\n",
    "\n",
    "from dijkstar import Graph, find_path\n",
    "from IPython.display import display\n",
    "\n",
    "import networkx as nx\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "path=\"images/current.jpg\"\n",
    "display(Image.open(path))\n",
    "\n",
    "filepath = \"images/current.jpg\"\n",
    "img = Image.open(filepath) \n",
    "  \n",
    "# get width and height \n",
    "width = img.width \n",
    "height = img.height\n",
    "\n",
    "print(width)\n",
    "print(height)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "549e49e7-f0f0-4d75-b3b6-001e592fdb75",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "obs_nbr = len(obstacle_coord)\n",
    "node_coord_x=[]\n",
    "node_coord_y=[]\n",
    "max_coord_y=height\n",
    "\n",
    "import math\n",
    "\n",
    "def distance(node1,node2):\n",
    "    distance=math.sqrt((node_coord_x[node2]-node_coord_x[node1])**2+(node_coord_y[node2]-node_coord_y[node1])**2)\n",
    "    distance=round(distance,2)\n",
    "    return distance\n",
    "def distance_goal_node(goal,node):\n",
    "    distance=math.sqrt((goal_coord_x[goal]-node_coord_x[node])**2+(goal_coord_y[goal]-node_coord_y[node])**2)\n",
    "    distance=round(distance,2)\n",
    "    return distance\n",
    "\n",
    "def distance_node_goal(node,goal):\n",
    "    distance=math.sqrt((goal_coord_x[goal]-node_coord_x[node])**2+(goal_coord_y[goal]-node_coord_y[node])**2)\n",
    "    distance=round(distance,2)\n",
    "    return distance\n",
    "\n",
    "# def Thymio_node_rt(thymio_coords, node):\n",
    "#     distance=math.sqrt((goal_coord_x[goal]-node_coord_x[node])**2+(goal_coord_y[goal]-node_coord_y[node])**2)\n",
    "#     distance=round(distance,2)\n",
    "#     return distance\n",
    "\n",
    "for obstacle in range(obs_nbr):\n",
    "    for corner_high in range(2):\n",
    "        node_coord_y.append(obstacle_coord[obstacle][(2*corner_high)+1]/2)\n",
    "        node_coord_x.append(obstacle_coord[obstacle][(2*corner_high)])\n",
    "    for corner_low in range(2):\n",
    "        node_coord_y.append(max_coord_y-((max_coord_y-obstacle_coord[obstacle][(2*corner_low)+5])/2))\n",
    "        node_coord_x.append(obstacle_coord[obstacle][(2*corner_low)+4])\n",
    "\n",
    "def draw_graph(graph_data):\n",
    "    # Créer un objet Graph avec networkx\n",
    "    G = nx.Graph()\n",
    "\n",
    "    # Ajouter des nœuds et des liens au graphique\n",
    "    for node, edges in graph_data.items():\n",
    "        G.add_node(node)\n",
    "        for neighbor, weight in edges.items():\n",
    "            G.add_edge(node, neighbor, weight=weight)\n",
    "\n",
    "    # Dessiner le graphique\n",
    "    pos = nx.spring_layout(G)  # position des nœuds pour un aspect plus lisible\n",
    "    labels = nx.get_edge_attributes(G, 'weight')\n",
    "    nx.draw(G, pos, with_labels=True, node_size=700, node_color=\"skyblue\", font_size=8)\n",
    "    nx.draw_networkx_edge_labels(G, pos, edge_labels=labels)\n",
    "\n",
    "    # Afficher le graphique\n",
    "    plt.show()\n",
    "\n",
    "graph = Graph ()\n",
    "def connect_nodes(obs_nbr):     \n",
    "    for nb_node in range(obs_nbr*4-1):\n",
    "        if nb_node % 2 == 0:\n",
    "            graph.add_edge(nb_node, nb_node + 1, distance(nb_node, nb_node + 1))\n",
    "            if nb_node > 3:\n",
    "                graph.add_edge(nb_node, nb_node -3, distance(nb_node, nb_node -3))\n",
    "                if nb_node % 4 == 0:\n",
    "                    graph.add_edge(nb_node, nb_node - 1, distance(nb_node, nb_node - 1))\n",
    "                else:\n",
    "                    graph.add_edge(nb_node, nb_node - 5, distance(nb_node, nb_node - 5))\n",
    "        else:\n",
    "            graph.add_edge(nb_node, nb_node - 1, distance(nb_node, nb_node - 1))\n",
    "            if nb_node < (obs_nbr-1)*4:\n",
    "                graph.add_edge(nb_node, nb_node + 3, distance(nb_node, nb_node + 3))\n",
    "                if (nb_node-1) % 4 == 0:\n",
    "                    graph.add_edge(nb_node, nb_node + 5, distance(nb_node, nb_node + 5))\n",
    "                else:\n",
    "                    graph.add_edge(nb_node, nb_node + 1, distance(nb_node, nb_node + 1))\n",
    "                    \n",
    "    # draw_graph(graph)\n",
    "    # shortest_path = find_path(graph, 0, 2)\n",
    "    # print(shortest_path)   \n",
    "    # return graph\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95bec5dd-2d80-44f7-9d4f-3e8051c33bf8",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "goal_coord_x=[center_thymio[0][0],center_goal[0]]   \n",
    "print(goal_coord_x)\n",
    "goal_coord_y=[center_thymio[0][1],center_goal[1]]\n",
    "print(goal_coord_y)\n",
    "thymio=100\n",
    "goal=101\n",
    "offset=obs_nbr*4\n",
    "\n",
    "def localisation(object):\n",
    "    column=0\n",
    "    break_flag=0\n",
    "    for obstacle in range(obs_nbr):\n",
    "        for corner in range(2):\n",
    "            \n",
    "            if goal_coord_x[object]<obstacle_coord[obstacle][(2*corner)]:\n",
    "                print(\"break\")\n",
    "                print(obstacle,corner)\n",
    "                break_flag=1\n",
    "                break\n",
    "            column+=1\n",
    "        if break_flag==1:\n",
    "            break\n",
    "            \n",
    "    print(column)\n",
    "    if column % 2 == 0:\n",
    "    \n",
    "        if column < 2 * obs_nbr:\n",
    "            graph.add_edge(object + offset, 2 * column, distance_goal_node(object, 2 * column))\n",
    "            graph.add_edge(2 * column, object + offset, distance_node_goal(2 * column, object))\n",
    "\n",
    "            graph.add_edge(object + offset, 2 * column + 2, distance_goal_node(object, 2 * column + 2))\n",
    "            graph.add_edge(2 * column + 2, object + offset, distance_node_goal(2 * column + 2, object))\n",
    "    \n",
    "        if column > 0:\n",
    "            graph.add_edge(object + offset, 2 * column - 1, distance_goal_node(object, 2 * column - 1))\n",
    "            graph.add_edge(2 * column - 1, object + offset, distance_node_goal(2 * column - 1, object))\n",
    "\n",
    "            graph.add_edge(object + offset, 2 * column - 3, distance_goal_node(object, 2 * column - 3))\n",
    "            graph.add_edge(2 * column - 3, object + offset, distance_node_goal(2 * column - 3, object))\n",
    "  \n",
    "    else:\n",
    "        if goal_coord_y[object] < obstacle_coord[math.floor((column - 1) / 2)][1]:\n",
    "            graph.add_edge(object + offset, (2 * column) - 1, distance_goal_node(object, (2 * column) - 1))\n",
    "            graph.add_edge((2 * column) - 1, object + offset, distance_node_goal((2 * column) - 1, object))\n",
    "\n",
    "            graph.add_edge(object + offset, (2 * column) - 2, distance_goal_node(object, (2 * column) - 2))\n",
    "            graph.add_edge((2 * column) - 2, object + offset, distance_node_goal((2 * column) - 2, object))\n",
    "        else:\n",
    "            graph.add_edge(object + offset, (2 * column), distance_goal_node(object, (2 * column)))\n",
    "            graph.add_edge((2 * column), object + offset, distance_node_goal((2 * column), object))\n",
    "\n",
    "            graph.add_edge(object + offset, (2 * column) + 1, distance_goal_node(object, (2 * column) + 1))\n",
    "            graph.add_edge((2 * column) + 1, object + offset, distance_node_goal((2 * column) + 1, object))\n",
    "\n",
    "connect_nodes(obs_nbr)\n",
    "localisation(0)\n",
    "localisation(1)\n",
    "\n",
    "draw_graph(graph)\n",
    "shortest_path = find_path(graph, 12, 13)\n",
    "print(shortest_path)\n",
    "            \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c93d1a4-86a4-4d6a-b829-fa0b676d0cf0",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "print(graph)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf2ff6d6-d247-44f3-8b93-a58863f19f66",
   "metadata": {},
   "source": [
    "## Global navigation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6746cf7c-44d2-4322-9d9c-86a69ef5ab05",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "clear()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c902447-001b-4023-aa16-d03d0a5758a7",
   "metadata": {},
   "source": [
    "## Get the Thymio center coordinates in real time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "ef1c8332-2cf4-4cdc-a22f-dbf630bfdf58",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def thymio_real_time(corners, ids):\n",
    "    # Get thymio at idx 0 and 1\n",
    "    idx_back = np.where(ids == 0)[0]\n",
    "    idx_fowards = np.where(ids == 1)[0]\n",
    "\n",
    "    if idx_back.size > 0 and idx_fowards.size > 0:\n",
    "        idx_back = idx_back[0]\n",
    "        idx_fowards = idx_fowards[0]\n",
    "\n",
    "        idx = [idx_back, idx_fowards]\n",
    "        coords = [corners[i].tolist() for i in idx]\n",
    "\n",
    "        center = []\n",
    "        for i in coords:\n",
    "            # Get center coordinates to return\n",
    "            x1 = i[0][0][0]\n",
    "            y1 = i[0][0][1]\n",
    "            x2 = i[0][2][0]\n",
    "            y2 = i[0][2][1]\n",
    "\n",
    "            x_center = (x1 + x2) / 2\n",
    "            y_center = (y1 + y2) / 2\n",
    "\n",
    "            center.append([x_center, y_center])\n",
    "\n",
    "        return center"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f8eb7e7-85e4-47f9-9365-bc5c2fe97cf8",
   "metadata": {},
   "source": [
    "## Main loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84ff620e-44fe-4cf2-a120-7d63cd41c616",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "!pip3 install tdmclient --upgrade"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e09c8125-e3a3-4297-9f2b-6a4ecdc26a19",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from tdmclient import ClientAsync, aw"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "801594c0-ba1d-479a-8ef2-173ed07924a6",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<tdmclient.clientasync.ClientAsync object at 0x00000278C5643290>\n"
     ]
    }
   ],
   "source": [
    "#Create a Client Object:\n",
    "client = ClientAsync()\n",
    "print(client)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9677e7bf-2a19-4f8f-bdff-300a15ae0152",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Node aab42e35-3b95-4e21-ac5a-4296aadae5f2]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "client.process_waiting_messages()\n",
    "print(client.nodes)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "cd649792-ca40-4271-99d3-e1cf253acc92",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "7f0bbda1-28d6-4ee9-bce8-40d4c0986fdd",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Node aab42e35-3b95-4e21-ac5a-4296aadae5f2]\n"
     ]
    }
   ],
   "source": [
    "#while True:\n",
    "print( client.nodes)\n",
    "node = client.nodes[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "2aa344e5-63d7-4da4-8060-f50f986aecc7",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Node aab42e35-3b95-4e21-ac5a-4296aadae5f2"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "aw(node.lock())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "07cf378d-c6df-4485-bdc8-b223b8dcec37",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "[[218.5, 14.0], [233.0, 68.0]]\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "[[221.5, 35.0], [239.0, 69.5]]\n",
      "None\n",
      "None\n",
      "None\n",
      "[[220.5, 36.0], [238.5, 70.5]]\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "[[239.0, 51.5], [251.5, 89.0]]\n",
      "[[239.5, 53.0], [251.5, 91.0]]\n",
      "None\n",
      "[[240.5, 55.0], [253.0, 94.0]]\n",
      "[[241.5, 57.0], [253.5, 95.5]]\n",
      "[[242.0, 58.5], [254.5, 96.0]]\n",
      "None\n",
      "[[243.0, 61.0], [254.5, 98.0]]\n",
      "[[243.5, 62.0], [255.5, 100.0]]\n",
      "[[244.0, 63.5], [255.5, 101.0]]\n",
      "None\n",
      "[[245.0, 66.0], [256.5, 104.0]]\n",
      "None\n",
      "None\n",
      "[[246.5, 69.5], [258.5, 108.5]]\n",
      "[[247.0, 70.5], [259.5, 108.0]]\n",
      "None\n",
      "None\n",
      "[[248.5, 74.5], [261.5, 112.0]]\n",
      "[[249.0, 76.0], [262.5, 114.0]]\n",
      "[[250.0, 78.0], [262.5, 115.5]]\n",
      "[[250.0, 78.0], [262.5, 116.0]]\n",
      "None\n",
      "None\n",
      "[[252.5, 83.0], [264.5, 120.0]]\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "[[255.0, 90.0], [267.0, 128.5]]\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "[[260.5, 104.0], [273.5, 142.0]]\n",
      "[[260.5, 104.0], [272.5, 142.5]]\n",
      "[[260.5, 104.5], [272.5, 142.0]]\n",
      "[[260.5, 104.5], [273.5, 142.0]]\n",
      "[[260.5, 106.0], [273.5, 143.0]]\n",
      "[[261.0, 106.0], [273.5, 142.5]]\n",
      "None\n",
      "None\n",
      "[[260.5, 106.0], [275.5, 142.5]]\n",
      "[[260.5, 106.0], [275.5, 142.0]]\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "[[260.0, 107.0], [276.5, 142.0]]\n",
      "None\n",
      "[[259.5, 107.5], [277.5, 142.5]]\n",
      "[[259.5, 107.5], [277.5, 142.5]]\n",
      "None\n",
      "[[259.5, 108.0], [277.0, 142.5]]\n",
      "None\n",
      "None\n",
      "[[259.0, 108.0], [275.5, 143.0]]\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "[[258.5, 109.5], [275.0, 144.0]]\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "[[257.5, 110.5], [271.0, 147.5]]\n"
     ]
    }
   ],
   "source": [
    "aruco_dict = aruco.getPredefinedDictionary(cv2.aruco.DICT_5X5_50)\n",
    "parameters = aruco.DetectorParameters()  \n",
    "detector = aruco.ArucoDetector(aruco_dict, parameters)\n",
    "\n",
    "cap = cv2.VideoCapture(1, cv2.CAP_DSHOW)  # Use 0 if you have only one camera\n",
    "\n",
    "# review asynch. programming\n",
    "while True:\n",
    "    # Setting motors\n",
    "    v = {\n",
    "        \"motor.left.target\": [50],\n",
    "        \"motor.right.target\": [50],\n",
    "    }\n",
    "    aw(node.set_variables(v))\n",
    "    #time.sleep(0.1)\n",
    "    \n",
    "    \n",
    "\n",
    "        # Read a frame from the camera\n",
    "    ret, frame = cap.read()\n",
    "\n",
    "    # Convert the frame to grayscale\n",
    "    gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
    "    # Detect markers\n",
    "    corners, ids, rejected_img_points = detector.detectMarkers(gray)\n",
    "   \n",
    "\n",
    "    \n",
    "\n",
    "    if np.all(ids is not None):\n",
    "        for i in range(len(ids)):\n",
    "            aruco.drawDetectedMarkers(frame, corners, ids)\n",
    "\n",
    "    # Display the frame\n",
    "    cv2.imshow('frame', frame)\n",
    "\n",
    "    thymio_coords = thymio_real_time(corners, ids)\n",
    "    print(thymio_coords)\n",
    "    \n",
    "    # Check for the 'q' key to exit the loop\n",
    "    key = cv2.waitKey(1) & 0xFF\n",
    "    if key == ord('q'):\n",
    "        break\n",
    "\n",
    "# Release the camera and close all OpenCV windows\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d9d9b13-d321-4a2d-8ba5-4597750a9921",
   "metadata": {},
   "outputs": [],
   "source": [
    "getpath90\n",
    "while true:\n",
    "    getpicture()\n",
    "    filter\n",
    "    controller()\n",
    "    thymio_motor()\n",
    "    "
   ]
  },
  {
   "cell_type": "raw",
   "id": "b40a22e4-bee2-406f-bbd0-f2bf6dbe079a",
   "metadata": {
    "tags": []
   },
   "source": [
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb45b0b5-d12d-4756-8901-5b57f9670172",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  },
  "toc-autonumbering": false,
  "toc-showcode": false,
  "toc-showmarkdowntxt": true,
  "toc-showtags": false
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
